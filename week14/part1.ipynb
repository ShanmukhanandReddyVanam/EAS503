{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1\n",
    "y = 2\n",
    "x\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "iris_dataset.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.california_housing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets.california_housing import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(houses.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.data.shape\n",
    "houses.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n",
      " 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n",
      " 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n",
      "  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n",
      "  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n",
      "  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n",
      "  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n",
      "  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n",
      " 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n",
      "  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n",
      " 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n",
      " 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n",
      " 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n",
      " 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n",
      "  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n",
      " 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n",
      "  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n",
      " 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n",
      "  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n",
      "  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n",
      " 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n",
      "  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n",
      " 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n",
      " 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n",
      " 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n",
      " 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n",
      " 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n",
      " 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n",
      " 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n",
      "  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n",
      " 146. 212. 233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.\n",
      "  49.  64.  48. 178. 104. 132. 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "data = load_diabetes()\n",
    "print(data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "x,y = make_regression(n_samples=100, n_features=1, noise=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.31715837]), 31.54588455279094)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "sns.regplot(x=x, y=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from openml.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice = fetch_openml(name='miceprotein', version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50364388, 0.74719322, 0.4301753 , 2.81632854, 5.99015166,\n",
       "       0.21883002, 0.17756549, 2.37374434, 0.23222375, 1.75093559,\n",
       "       0.68790624, 0.30638172, 0.40269844, 0.29692732, 1.02206027,\n",
       "       0.60567264, 1.87768367, 2.30874532, 0.44159937, 0.85936577,\n",
       "       0.41628915, 0.36960804, 0.17894426, 1.86635809, 3.68524719,\n",
       "       1.53722671, 0.2645263 , 0.31967697, 0.81386646, 0.16584597,\n",
       "       0.45390979, 3.03762064, 0.36950955, 0.45853851, 0.33533583,\n",
       "       0.82519204, 0.5769155 , 0.44809927, 0.58627142, 0.39472129,\n",
       "       0.33957061, 0.4828639 , 0.29416979, 0.18215047, 0.84272515,\n",
       "       0.19260839, 1.44309067, 0.29469997, 0.35460453, 1.33906996,\n",
       "       0.17011879, 0.15910245, 0.18885166, 0.10630521, 0.14498934,\n",
       "       0.17666768, 0.12519037, 0.11529089, 0.22804346, 0.14275561,\n",
       "       0.43095746, 0.24753782, 1.60330998, 2.01487461, 0.10823434,\n",
       "       1.04497919, 0.8315565 , 0.18885166, 0.12265205,        nan,\n",
       "       0.10630521, 0.10833587, 0.4270992 , 0.11478323, 0.13179003,\n",
       "       0.1281856 , 1.67565235])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mice.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d = np.random.rand(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 77)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mice.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Clara Higuera, Katheleen J. Gardiner, Krzysztof J. Cios  \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression) - 2015   \n",
      "**Please cite**: Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126.\n",
      "\n",
      "Expression levels of 77 proteins measured in the cerebral cortex of 8 classes of control and Down syndrome mice exposed to context fear conditioning, a task used to assess associative learning.\n",
      "\n",
      "The data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse. \n",
      "\n",
      "The eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not. \n",
      "\n",
      "Classes: \n",
      "```\n",
      "* c-CS-s: control mice, stimulated to learn, injected with saline (9 mice) \n",
      "* c-CS-m: control mice, stimulated to learn, injected with memantine (10 mice) \n",
      "* c-SC-s: control mice, not stimulated to learn, injected with saline (9 mice) \n",
      "* c-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice) \n",
      "* t-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice) \n",
      "* t-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice) \n",
      "* t-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice) \n",
      "* t-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice) \n",
      "```\n",
      "\n",
      "The aim is to identify subsets of proteins that are discriminant between the classes. \n",
      "\n",
      "### Attribute Information:\n",
      "\n",
      "```\n",
      "1 Mouse ID \n",
      "2..78 Values of expression levels of 77 proteins; the names of proteins are followed by &acirc;&euro;&oelig;_n&acirc;&euro; indicating that they were measured in the nuclear fraction. For example: DYRK1A_n \n",
      "79 Genotype: control (c) or trisomy (t) \n",
      "80 Treatment type: memantine (m) or saline (s) \n",
      "81 Behavior: context-shock (CS) or shock-context (SC) \n",
      "82 Class: c-CS-s, c-CS-m, c-SC-s, c-SC-m, t-CS-s, t-CS-m, t-SC-s, t-SC-m \n",
      "```\n",
      "\n",
      "### Relevant Papers:\n",
      "\n",
      "Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126 \n",
      "\n",
      "Ahmed MM, Dhanasekaran AR, Block A, Tong S, Costa ACS, Stasko M, et al. (2015) Protein Dynamics Associated with Failed and Rescued Learning in the Ts65Dn Mouse Model of Down Syndrome. PLoS ONE 10(3): e0119491.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "print(mice.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mice.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3. Preprocessing data\n",
    "\n",
    "## Standardization, or mean removal and variance scaling\n",
    "\n",
    "Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "X_scaled = preprocessing.scale(X_train)\n",
    "\n",
    "X_scaled      \n",
    "\n",
    "#rows are different patients/subjects/flowers\n",
    "# columns are various features of the patients/subjects/flowers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.84333333, 3.05733333, 3.758     , 1.19933333])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1.69031455e-15, -1.84297022e-15, -1.69864123e-15, -1.40924309e-15])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idata = iris_dataset.data\n",
    "id_scaled = preprocessing.scale(idata)\n",
    "idata.mean(axis=0)\n",
    "id_scaled.mean(axis=0)\n",
    "id_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.33333333])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0)\n",
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03718711,  0.31916121, -0.35634832])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04587533, 0.64957343, 1.11980724])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.std(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can save scaling and apply to testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "                                      \n",
    "scaler.transform(X_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.44948974,  1.22474487, -0.26726124]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = [[-1., 1., 0.]]\n",
    "scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Scaling features to a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5       ,  0.        ,  1.66666667]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[-3., -1.,  4.]])\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "X_test_minmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing data - Non-linear transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>International airline passengers: monthly tota...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  date  passengers\n",
       "0                                              1949-01       112.0\n",
       "1                                              1949-02       118.0\n",
       "2                                              1949-03       132.0\n",
       "3                                              1949-04       129.0\n",
       "4                                              1949-05       121.0\n",
       "..                                                 ...         ...\n",
       "140                                            1960-09       508.0\n",
       "141                                            1960-10       461.0\n",
       "142                                            1960-11       390.0\n",
       "143                                            1960-12       432.0\n",
       "144  International airline passengers: monthly tota...         NaN\n",
       "\n",
       "[145 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "df = pd.read_csv('international-airline-passengers.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'passengers'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['passengers'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['passengers'] = np.log(df['passengers'])\n",
    "df['passengers'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25, -0.25,  0.5 ],\n",
       "       [ 1.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.5 , -0.5 ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "X_normalized = preprocessing.normalize(X, norm='l1')\n",
    "\n",
    "X_normalized   \n",
    "# http://www.chioka.in/differences-between-the-l1-norm-and-the-l2-norm-least-absolute-deviations-and-least-squares/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can save the normalization for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalizer()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalizer().fit(X)  # fit does nothing\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.transform(X)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = normalizer.transform([[2.,  1., 0.]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89442719, 0.4472136 , 0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4472135954999579"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp*tmp).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data - Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], \n",
    "     ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['female', 'from US', 'uses Safari']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['male', 'from Europe', 'uses Safari']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories=[['female', 'male'],\n",
       "                          ['from Africa', 'from Asia', 'from Europe',\n",
       "                           'from US'],\n",
       "                          ['uses Chrome', 'uses Firefox', 'uses IE',\n",
       "                           'uses Safari']])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Africa', 'from Asia', 'from Europe', 'from US'], dtype=object),\n",
       " array(['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X) \n",
    "enc.categories_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = enc.transform([['female', 'from Asia', 'uses Chrome'],\n",
    "                    ['male', 'from Europe', 'uses Safari']]).toarray()\n",
    "tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0, 1, 0, 0, 1, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['female', 'from Asia', 'uses Chrome'],\n",
       "       ['male', 'from Europe', 'uses Safari']], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.5. Discretization\n",
    "\n",
    "Discretization (otherwise known as quantization or binning) provides a way to partition continuous features into discrete values. Certain datasets with continuous features may benefit from discretization, because discretization can transform the dataset of continuous attributes to one with only nominal attributes.\n",
    "\n",
    "One-hot encoded discretized features can make a model more expressive, while maintaining interpretability. For instance, pre-processing with a discretizer can introduce nonlinearity to linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ -3., 5., 15 ],\n",
    "              [  0., 6., 14 ],\n",
    "              [  6., 3., 11 ]])\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=[3, 2, 4], encode='ordinal').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 3.],\n",
       "       [1., 1., 2.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/preprocessing.html#k-bins-discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4.2. Univariate feature imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.         2.        ]\n",
      " [6.         3.66666667]\n",
      " [7.         6.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit([[1, 2],\n",
    "         [np.nan, 3], \n",
    "         [7, 6]])  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = [[np.nan, 2], \n",
    "     [6, np.nan], \n",
    "     [7, 6]]\n",
    "print(imp.transform(X))      \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6666666666666665"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a' 'x']\n",
      " ['a' 'y']\n",
      " ['a' 'y']\n",
      " ['b' 'y']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([[\"a\", \"x\"],\n",
    "                   [np.nan, \"y\"],\n",
    "                   [\"a\", np.nan],\n",
    "                   [\"b\", \"y\"]], dtype=\"category\")\n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "print(imp.fit_transform(df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a' 'x']\n",
      " ['a' 'y']\n",
      " ['c' 'y']\n",
      " ['b' 'y']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([[\"a\", \"x\"],\n",
    "                   [np.nan, \"y\"],\n",
    "                   [\"c\", np.nan],\n",
    "                   [\"b\", \"y\"]], dtype=\"category\")\n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "print(imp.fit_transform(df)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.arange(10).reshape((5, 2)), [0, 1, 0, 0, 1]\n",
    "X\n",
    "list(y)\n",
    "# X -- feature\n",
    "# y -- label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [6, 7],\n",
       "       [0, 1],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[8, 9]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "\n",
    "X_train\n",
    "\n",
    "y_train\n",
    "\n",
    "X_test\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [0, 1],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 1]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[6, 7],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=43)\n",
    "\n",
    "X_train\n",
    "\n",
    "y_train\n",
    "\n",
    "X_test\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5],\n",
       "       [0, 1],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train\n",
    "\n",
    "y_train\n",
    "\n",
    "X_test\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [8, 9],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 0]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[4, 5],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=np.random)\n",
    "\n",
    "X_train\n",
    "\n",
    "y_train\n",
    "\n",
    "X_test\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=np.random)\n",
    "\n",
    "X_train\n",
    "\n",
    "y_train\n",
    "\n",
    "X_test\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "diabetes.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = diabetes.feature_names\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018118  0.044485  \n",
       "439 -0.011080 -0.046879  0.015491  \n",
       "440  0.026560  0.044528 -0.025930  \n",
       "441 -0.039493 -0.004220  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(diabetes.data, columns=feature_names)\n",
    "y = diabetes.target\n",
    "df\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.001895</td>\n",
       "      <td>0.066630</td>\n",
       "      <td>0.090620</td>\n",
       "      <td>0.108914</td>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>-0.035817</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.074533</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.018062</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>-0.019456</td>\n",
       "      <td>-0.024800</td>\n",
       "      <td>-0.065491</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.067317</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.045341</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>-0.009825</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.015505</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.041180</td>\n",
       "      <td>-0.071494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.024529</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>0.098876</td>\n",
       "      <td>0.094196</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.021394</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016281</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>-0.022885</td>\n",
       "      <td>0.060349</td>\n",
       "      <td>0.044406</td>\n",
       "      <td>0.030232</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.037232</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-0.052738</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.062252</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>0.122273</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.023546</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>-0.012556</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.038769</td>\n",
       "      <td>0.063367</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.066048</td>\n",
       "      <td>0.048628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.059871</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.076786</td>\n",
       "      <td>0.025315</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.016849</td>\n",
       "      <td>-0.054446</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.029936</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-0.092695</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.081653</td>\n",
       "      <td>-0.057314</td>\n",
       "      <td>-0.060735</td>\n",
       "      <td>-0.068014</td>\n",
       "      <td>0.048640</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.066488</td>\n",
       "      <td>-0.021788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.080019</td>\n",
       "      <td>0.098763</td>\n",
       "      <td>-0.002945</td>\n",
       "      <td>0.018101</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>-0.029528</td>\n",
       "      <td>0.036201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "7    0.063504  0.050680 -0.001895  0.066630  0.090620  0.108914  0.022869   \n",
       "185 -0.074533  0.050680 -0.018062  0.008101 -0.019456 -0.024800 -0.065491   \n",
       "85   0.045341 -0.044642  0.071397  0.001215 -0.009825 -0.001001  0.015505   \n",
       "418  0.009016 -0.044642 -0.024529 -0.026328  0.098876  0.094196  0.070730   \n",
       "100  0.016281 -0.044642  0.017506 -0.022885  0.060349  0.044406  0.030232   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "266 -0.052738  0.050680 -0.062252  0.011544 -0.008449 -0.036700  0.122273   \n",
       "239  0.023546 -0.044642  0.019662 -0.012556  0.083740  0.038769  0.063367   \n",
       "290  0.059871  0.050680  0.076786  0.025315  0.001183  0.016849 -0.054446   \n",
       "136 -0.092695 -0.044642 -0.081653 -0.057314 -0.060735 -0.068014  0.048640   \n",
       "416 -0.027310 -0.044642  0.080019  0.098763 -0.002945  0.018101 -0.017629   \n",
       "\n",
       "           s4        s5        s6  \n",
       "7    0.017703 -0.035817  0.003064  \n",
       "185  0.034309  0.067317 -0.017646  \n",
       "85  -0.039493 -0.041180 -0.071494  \n",
       "418 -0.002592 -0.021394  0.007207  \n",
       "100 -0.002592  0.037232 -0.001078  \n",
       "..        ...       ...       ...  \n",
       "266 -0.076395 -0.086829  0.003064  \n",
       "239 -0.002592  0.066048  0.048628  \n",
       "290  0.034309  0.029936  0.044485  \n",
       "136 -0.076395 -0.066488 -0.021788  \n",
       "416  0.003312 -0.029528  0.036201  \n",
       "\n",
       "[353 rows x 10 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 63., 101., 141.,  84., 128., 280.,  49.,  66., 132.,  81., 143.,\n",
       "        90.,  51., 214., 200., 219., 127., 212., 253., 109.,  77., 245.,\n",
       "       142., 198.,  55., 111., 104., 293., 242.,  84., 202., 308.,  78.,\n",
       "       346., 208., 252.,  60.,  96.,  52.,  48., 189., 139.,  49., 201.,\n",
       "       275., 150.,  70., 168., 141.,  92.,  72.,  74., 178.,  72., 225.,\n",
       "       147., 100., 181., 131., 233., 252.,  65., 292.,  71.,  88., 103.,\n",
       "        64., 235., 274., 190., 134., 125.,  48.,  52.,  66.,  64., 310.,\n",
       "        85.,  91., 179.,  47., 144.,  95., 198., 152., 115., 279., 113.,\n",
       "        60., 192.,  53.,  58., 158., 270., 137., 276.,  84., 160.,  52.,\n",
       "       197., 150., 110., 265., 190., 135., 191., 199., 180.,  77., 215.,\n",
       "       184., 200.,  39., 155., 103., 241., 310., 272., 138., 264., 175.,\n",
       "       118., 129.,  83., 306., 158., 259., 122., 258.,  88., 162., 107.,\n",
       "       180.,  57.,  72.,  85., 237., 150., 122.,  53., 107., 275.,  97.,\n",
       "        43.,  48., 115., 216., 163., 275.,  95., 142., 168.,  64., 104.,\n",
       "        65.,  60.,  92., 128.,  68., 187., 111.,  85., 109., 302.,  78.,\n",
       "       156.,  84., 219.,  77.,  59.,  49.,  63., 174., 206.,  99., 144.,\n",
       "       281., 230., 220., 283.,  94., 233., 178., 259.,  71., 249., 297.,\n",
       "        51., 170., 172., 104., 281.,  86., 230., 341., 321., 140., 246.,\n",
       "       124.,  63.,  94., 196.,  96., 296., 202., 138., 144.,  80., 154.,\n",
       "        72., 102.,  69.,  71., 131.,  69., 270., 220.,  31., 206., 173.,\n",
       "       170., 136., 273., 183., 222., 195.,  63., 163.,  91., 140., 252.,\n",
       "       168., 129.,  59.,  91.,  89., 225.,  55.,  59., 248.,  54.,  68.,\n",
       "       177.,  78., 128., 275., 246., 186., 200., 161., 127.,  53., 178.,\n",
       "        97., 243.,  61., 191.,  83., 151., 174.,  68.,  77., 134., 109.,\n",
       "       257., 242., 121., 248., 197.,  91., 259., 258., 135., 113.,  90.,\n",
       "       262.,  71., 196., 288., 108., 283., 237., 171.,  65., 164., 111.,\n",
       "        81., 272., 101., 116., 265.,  75., 235., 113.,  40.,  74., 303.,\n",
       "        44.,  42., 131., 114.,  96.,  72.,  67., 233.,  93., 170.,  75.,\n",
       "       214.,  93.,  97., 265.,  97., 236., 263., 277., 210., 220., 145.,\n",
       "       124., 244., 178., 232., 232., 137., 311., 281.,  55.,  87.,  53.,\n",
       "       261., 214., 148., 295.,  83., 263., 139., 167., 242.,  61., 164.,\n",
       "        90., 120.,  67., 141., 182., 123., 258.,  45., 262., 332.,  85.,\n",
       "       257.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.069241</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>-0.023234</td>\n",
       "      <td>-0.047082</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.103292</td>\n",
       "      <td>0.073480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.067136</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>-0.084857</td>\n",
       "      <td>-0.007073</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>-0.054446</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.032059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.085430</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.040696</td>\n",
       "      <td>-0.033214</td>\n",
       "      <td>-0.081374</td>\n",
       "      <td>-0.069580</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.057800</td>\n",
       "      <td>-0.042499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.034443</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.001895</td>\n",
       "      <td>-0.012556</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.078093</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>-0.096346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.027310</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.007284</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.011201</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>0.059685</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.082381</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.034443</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.007284</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.037326</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.021394</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-0.030942</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.031567</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.078165</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.016984</td>\n",
       "      <td>-0.012556</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>-0.013527</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.041180</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.049105</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.005128</td>\n",
       "      <td>-0.046985</td>\n",
       "      <td>-0.020832</td>\n",
       "      <td>-0.020416</td>\n",
       "      <td>-0.069172</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.061238</td>\n",
       "      <td>-0.038357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "390  0.009016  0.050680  0.069241  0.059744  0.017694 -0.023234 -0.047082   \n",
       "278  0.067136  0.050680 -0.036385 -0.084857 -0.007073  0.019667 -0.054446   \n",
       "351 -0.085430  0.050680 -0.040696 -0.033214 -0.081374 -0.069580 -0.006584   \n",
       "127  0.034443  0.050680 -0.001895 -0.012556  0.038334  0.013717  0.078093   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "62  -0.027310  0.050680 -0.007284 -0.040099 -0.011201 -0.013840  0.059685   \n",
       "50   0.034443 -0.044642 -0.007284  0.014987 -0.044223 -0.037326 -0.002903   \n",
       "146 -0.030942  0.050680  0.059541  0.001215  0.012191  0.031567 -0.043401   \n",
       "94  -0.078165 -0.044642 -0.016984 -0.012556 -0.000193 -0.013527  0.070730   \n",
       "149 -0.049105  0.050680 -0.005128 -0.046985 -0.020832 -0.020416 -0.069172   \n",
       "\n",
       "           s4        s5        s6  \n",
       "390  0.034309  0.103292  0.073480  \n",
       "278  0.034309  0.001144  0.032059  \n",
       "351 -0.039493 -0.057800 -0.042499  \n",
       "127 -0.039493  0.004552 -0.096346  \n",
       "438  0.034309 -0.018118  0.044485  \n",
       "..        ...       ...       ...  \n",
       "62  -0.039493 -0.082381 -0.025930  \n",
       "50  -0.039493 -0.021394  0.007207  \n",
       "146  0.034309  0.014823  0.007207  \n",
       "94  -0.039493 -0.041180 -0.092204  \n",
       "149  0.071210  0.061238 -0.038357  \n",
       "\n",
       "[89 rows x 10 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([277., 102.,  71., 109., 104., 116., 185., 132., 217., 181.,  90.,\n",
       "       202.,  47.,  51., 245., 102.,  72., 142., 131., 143.,  50.,  70.,\n",
       "       281.,  98., 182., 166., 292., 110.,  37., 200.,  39., 152., 129.,\n",
       "       185., 185.,  42.,  87.,  96., 200., 118.,  88., 121., 142., 202.,\n",
       "        25., 101., 229., 182.,  99., 200., 128., 243., 179., 160.,  94.,\n",
       "        89.,  73., 118.,  42.,  55., 153.,  88., 146., 144., 248., 150.,\n",
       "       268., 151.,  59., 198., 220., 268.,  69., 172., 217.,  79.,  65.,\n",
       "       317., 221., 310., 151., 173., 209., 336.,  52., 155., 178.,  90.,\n",
       "       126.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.2, random_state=np.random)\n",
    "\n",
    "X_train\n",
    "\n",
    "y_train\n",
    "\n",
    "X_test\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 10)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(89, 10)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "\n",
    "len(y_train)\n",
    "\n",
    "X_test.shape\n",
    "\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression \n",
    "Ref: https://www.kaggle.com/getting-started/59856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# y = 1 * x_0 + 2 * x_1 + 3\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)\n",
    "\n",
    "reg.coef_\n",
    "\n",
    "reg.intercept_ \n",
    "\n",
    "reg.predict(np.array([[3, 5]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('Salary_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train,y_train,color='red')\n",
    "plt.plot(X_train,regressor.predict(X_train),color='blue')\n",
    "plt.title('Salary VS Experience (Training Data)')\n",
    "plt.xlabel('Years of experiene')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_test,y_test,color='red')\n",
    "plt.plot(X_test,regressor.predict(X_test),color='blue')\n",
    "plt.title('Salary VS Experience (Test Data)');\n",
    "plt.xlabel('Years of experiene');\n",
    "plt.ylabel('Salary');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The indices of the features that we are plotting\n",
    "x_index = 0\n",
    "y_index = 1\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index], c=iris.target)\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdata = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(irisdata.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdata.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdata.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = irisdata.data\n",
    "Y = irisdata.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400 \n",
    "380 # B\n",
    "20 # M\n",
    "\n",
    "380/400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
